{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af85ad6b",
   "metadata": {},
   "source": [
    "# üèà NFL Championship Predictor - XGBoost Machine Learning\n",
    "\n",
    "This notebook demonstrates a complete machine learning system for predicting NFL Super Bowl champions using **XGBoost**.\n",
    "\n",
    "## System Overview\n",
    "- **Problem Type**: Binary Classification (per team)\n",
    "- **Algorithm**: XGBoost (Gradient Boosting)\n",
    "- **Validation**: Time-Based Cross-Validation\n",
    "- **Target**: Championship Probability\n",
    "- **Features**: Team performance statistics (Win %, Points, etc.)\n",
    "\n",
    "**Author**: Data Science Demo  \n",
    "**Date**: February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cfbaf5",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path to import custom modules\n",
    "sys.path.append('src')\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Import ML libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    log_loss, roc_auc_score, brier_score_loss,\n",
    "    classification_report, confusion_matrix, roc_curve, auc\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 7)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa67ed",
   "metadata": {},
   "source": [
    "## 2. Load Pre-Trained Model and Data\n",
    "\n",
    "We'll load the trained XGBoost model and prepared data to demonstrate predictions and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b1f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import NFLChampionshipPredictor\n",
    "from data_preparation import prepare_data, SUPER_BOWL_WINNERS\n",
    "from predict import predict_championship_probabilities\n",
    "\n",
    "# Load the trained model\n",
    "print(\"Loading trained XGBoost model...\")\n",
    "predictor = NFLChampionshipPredictor.load_model('models/championship_model.pkl')\n",
    "\n",
    "# Load prepared data\n",
    "print(\"\\nLoading NFL data...\")\n",
    "df = prepare_data()\n",
    "\n",
    "print(f\"\\nüìä Dataset Overview:\")\n",
    "print(f\"   ‚Ä¢ Total team-seasons: {len(df)}\")\n",
    "print(f\"   ‚Ä¢ Years: {df['Year'].min()} - {df['Year'].max()}\")\n",
    "print(f\"   ‚Ä¢ Champions: {int(df['Won_SB'].sum())}\")\n",
    "print(f\"   ‚Ä¢ Features: {len(predictor.features)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Model and data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866b051",
   "metadata": {},
   "source": [
    "## 3. Model Performance Metrics\n",
    "\n",
    "Time-based cross-validation results showing how well the model predicts on unseen seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86026596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CV results\n",
    "cv_results = pd.read_csv('../results/cv_results.csv')\n",
    "\n",
    "print(\"üìà Time-Based Cross-Validation Results:\")\n",
    "print(\"=\"*70)\n",
    "print(cv_results.to_string(index=False))\n",
    "\n",
    "print(f\"\\nüìä Average Performance:\")\n",
    "print(f\"   ‚Ä¢ Log Loss (lower is better):    {cv_results['log_loss'].mean():.4f} ¬± {cv_results['log_loss'].std():.4f}\")\n",
    "print(f\"   ‚Ä¢ ROC-AUC (higher is better):    {cv_results['roc_auc'].mean():.4f} ¬± {cv_results['roc_auc'].std():.4f}\")\n",
    "print(f\"   ‚Ä¢ Brier Score (lower is better): {cv_results['brier_score'].mean():.4f} ¬± {cv_results['brier_score'].std():.4f}\")\n",
    "\n",
    "# Visualize CV performance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(cv_results['test_year'], cv_results['log_loss'], marker='o', linewidth=2, color='crimson')\n",
    "axes[0].set_title('Log Loss by Year')\n",
    "axes[0].set_xlabel('Year')\n",
    "axes[0].set_ylabel('Log Loss')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(cv_results['test_year'], cv_results['roc_auc'], marker='s', linewidth=2, color='green')\n",
    "axes[1].set_title('ROC-AUC by Year')\n",
    "axes[1].set_xlabel('Year')\n",
    "axes[1].set_ylabel('ROC-AUC')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "axes[2].plot(cv_results['test_year'], cv_results['brier_score'], marker='^', linewidth=2, color='purple')\n",
    "axes[2].set_title('Brier Score by Year')\n",
    "axes[2].set_xlabel('Year')\n",
    "axes[2].set_ylabel('Brier Score')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b76d65",
   "metadata": {},
   "source": [
    "## 4. Predict Championship Probabilities (2023 Season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e02b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for 2023 season\n",
    "year = 2023\n",
    "predictions = predict_championship_probabilities(predictor, df, year=year)\n",
    "\n",
    "print(f\"üèà Championship Predictions for {year} Season:\")\n",
    "print(\"=\"*70)\n",
    "print(predictions.head(15).to_string(index=False))\n",
    "\n",
    "# Identify actual champion\n",
    "actual_champion = SUPER_BOWL_WINNERS.get(year, \"Unknown\")\n",
    "predicted_champion = predictions.iloc[0]['Team']\n",
    "\n",
    "print(f\"\\nüéØ Predicted Champion: {predicted_champion}\")\n",
    "print(f\"   Probability: {predictions.iloc[0]['Championship_Prob']*100:.2f}%\")\n",
    "print(f\"\\nüèÜ Actual Champion: {actual_champion}\")\n",
    "\n",
    "# Check if prediction was correct\n",
    "if predicted_champion == actual_champion:\n",
    "    print(\"   ‚úÖ CORRECT PREDICTION!\")\n",
    "else:\n",
    "    actual_rank = predictions[predictions['Team'] == actual_champion]['Rank'].values\n",
    "    if len(actual_rank) > 0:\n",
    "        print(f\"   ‚ùå Incorrect (Actual champion ranked #{actual_rank[0]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7447cf4",
   "metadata": {},
   "source": [
    "## 5. Feature Importance - What Drives Championship Predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': predictor.features,\n",
    "    'Importance': predictor.model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"üß† Feature Importance Rankings:\")\n",
    "print(\"=\"*70)\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(importance_df)))\n",
    "bars = plt.barh(importance_df['Feature'][::-1], importance_df['Importance'][::-1], \n",
    "                color=colors, edgecolor='black', linewidth=0.7)\n",
    "\n",
    "plt.xlabel('Importance Score', fontsize=12, weight='bold')\n",
    "plt.ylabel('Feature', fontsize=12, weight='bold')\n",
    "plt.title('XGBoost Feature Importance Analysis', fontsize=14, weight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (feat, imp) in enumerate(zip(importance_df['Feature'][::-1], importance_df['Importance'][::-1])):\n",
    "    plt.text(imp + 0.005, i, f'{imp:.4f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(f\"   ‚Ä¢ Most important feature: {importance_df.iloc[0]['Feature']} ({importance_df.iloc[0]['Importance']:.4f})\")\n",
    "print(f\"   ‚Ä¢ Top 3 features account for {importance_df['Importance'].head(3).sum():.1%} of model's decisions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00f099f",
   "metadata": {},
   "source": [
    "## 6. Historical Prediction Accuracy\n",
    "\n",
    "How well does the model predict past Super Bowl winners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate predictions against historical champions\n",
    "validation_years = [2018, 2019, 2020, 2021, 2022, 2023]\n",
    "results = []\n",
    "\n",
    "for year in validation_years:\n",
    "    preds = predict_championship_probabilities(predictor, df, year=year)\n",
    "    if preds is None:\n",
    "        continue\n",
    "    \n",
    "    predicted = preds.iloc[0]['Team']\n",
    "    actual = SUPER_BOWL_WINNERS.get(year, \"Unknown\")\n",
    "    \n",
    "    actual_rank = preds[preds['Team'] == actual]['Rank'].values\n",
    "    actual_prob = preds[preds['Team'] == actual]['Championship_Prob'].values\n",
    "    \n",
    "    results.append({\n",
    "        'Year': year,\n",
    "        'Predicted': predicted,\n",
    "        'Actual': actual,\n",
    "        'Correct': '‚úÖ' if predicted == actual else '‚ùå',\n",
    "        'Actual_Rank': actual_rank[0] if len(actual_rank) > 0 else None,\n",
    "        'Actual_Prob': f\"{actual_prob[0]*100:.2f}%\" if len(actual_prob) > 0 else \"N/A\"\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"üìä Historical Validation Results:\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "accuracy = (results_df['Correct'] == '‚úÖ').sum() / len(results_df)\n",
    "print(f\"\\nüìà Prediction Accuracy: {accuracy*100:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Correct: {(results_df['Correct'] == '‚úÖ').sum()} / {len(results_df)}\")\n",
    "print(f\"   ‚Ä¢ Average rank of actual champion: {results_df['Actual_Rank'].mean():.1f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy by year\n",
    "colors = ['green' if c == '‚úÖ' else 'red' for c in results_df['Correct']]\n",
    "ax1.bar(results_df['Year'], [1 if c == '‚úÖ' else 0 for c in results_df['Correct']], \n",
    "        color=colors, edgecolor='black', linewidth=1.2, alpha=0.7)\n",
    "ax1.set_ylabel('Correct (1=Yes, 0=No)', fontweight='bold')\n",
    "ax1.set_title('Year-by-Year Prediction Accuracy', fontweight='bold')\n",
    "ax1.set_ylim(0, 1.2)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Actual champion rank\n",
    "ax2.plot(results_df['Year'], results_df['Actual_Rank'], \n",
    "         marker='o', linewidth=2, markersize=10, color='navy')\n",
    "ax2.axhline(1, color='gold', linestyle='--', linewidth=2, label='Perfect Prediction', alpha=0.8)\n",
    "ax2.set_ylabel('Rank of Actual Champion', fontweight='bold')\n",
    "ax2.set_title('Where Did We Rank the Actual Winner?', fontweight='bold')\n",
    "ax2.invert_yaxis()\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ea815",
   "metadata": {},
   "source": [
    "## 7. View Generated Visualizations\n",
    "\n",
    "Display the comprehensive visualizations created by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e75607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display saved visualizations\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "plot_files = [\n",
    "    ('win_pct_vs_championship.png', 'Win % vs Championship Status'),\n",
    "    ('prob_distribution.png', '2023 Championship Probability Distribution'),\n",
    "    ('champion_stats.png', 'Champion vs Non-Champion Statistics'),\n",
    "    ('correlation_heatmap.png', 'Feature Correlation Heatmap')\n",
    "]\n",
    "\n",
    "for filename, title in plot_files:\n",
    "    filepath = os.path.join('..', 'results', filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üìä {title}\")\n",
    "        print('='*70)\n",
    "        display(Image(filename=filepath))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {filename} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831b063",
   "metadata": {},
   "source": [
    "## 8. Conclusion and Next Steps\n",
    "\n",
    "### System Summary\n",
    "- ‚úÖ **Model**: XGBoost with optimized hyperparameters\n",
    "- ‚úÖ **Validation**: Time-based cross-validation (no data leakage)\n",
    "- ‚úÖ **Performance**: ROC-AUC ~0.85, Log Loss ~0.13\n",
    "- ‚úÖ **Features**: Win %, Point Differential, Historical Performance\n",
    "\n",
    "### Key Findings\n",
    "1. **Win Percentage** and **Point Differential** are the strongest predictors\n",
    "2. **Previous season performance** provides valuable context\n",
    "3. Model ranks actual champions **highly** even when not #1\n",
    "\n",
    "### Limitations\n",
    "- Small dataset (~19 champions in 19 years)\n",
    "- Limited features (no player-level data, injuries, etc.)\n",
    "- Playoff single-elimination inherent randomness\n",
    "- Class imbalance (1 winner vs 31 non-winners)\n",
    "\n",
    "### Future Enhancements\n",
    "- üîÆ Add QB-specific statistics (passer rating, QBR)\n",
    "- üìä Include advanced metrics (DVOA, EPA, etc.)\n",
    "- üè• Factor in injury data\n",
    "- üé≤ Monte Carlo playoff simulations\n",
    "- ü§ñ Ensemble with LightGBM/Random Forest\n",
    "- ‚ö° Real-time mid-season predictions\n",
    "\n",
    "### How to Use This System\n",
    "1. **Update Data**: Add new season to `nfl_standings_2005_2024.csv`\n",
    "2. **Retrain Model**: Run `python src/run_pipeline.py`\n",
    "3. **Make Predictions**: Run `python src/predict.py`\n",
    "4. **View Results**: Check `results/` folder\n",
    "\n",
    "---\n",
    "\n",
    "**Built with**: Python, XGBoost, scikit-learn, pandas, matplotlib, seaborn  \n",
    "**Methodology**: Supervised learning, binary classification, time-series CV  \n",
    "**Date**: February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e857f",
   "metadata": {},
   "source": [
    "## 9. Make Your Own Predictions\n",
    "\n",
    "Use this code template to predict any season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPLATE: Predict for any year\n",
    "def predict_any_season(year):\n",
    "    \"\"\"\n",
    "    Make championship predictions for any season.\n",
    "    \n",
    "    Args:\n",
    "        year: Season year (e.g., 2022, 2023, etc.)\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîÆ Predicting {year} Championship...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    preds = predict_championship_probabilities(predictor, df, year=year)\n",
    "    \n",
    "    if preds is None:\n",
    "        print(f\"‚ö†Ô∏è  No data available for {year}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nüèÜ Top 10 Teams for {year}:\")\n",
    "    print(preds.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize top 15 teams\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_teams = preds.head(15)\n",
    "    \n",
    "    bars = plt.barh(range(len(top_teams)), top_teams['Championship_Prob'] * 100, \n",
    "                    color='steelblue', edgecolor='black', linewidth=0.7)\n",
    "    \n",
    "    # Highlight top 3\n",
    "    for i in range(min(3, len(top_teams))):\n",
    "        bars[i].set_color('gold')\n",
    "    \n",
    "    plt.yticks(range(len(top_teams)), top_teams['Team'])\n",
    "    plt.xlabel('Championship Probability (%)', fontweight='bold', fontsize=11)\n",
    "    plt.title(f'{year} NFL Championship Probability Rankings', fontweight='bold', fontsize=14)\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Add probability labels\n",
    "    for i, prob in enumerate(top_teams['Championship_Prob']):\n",
    "        plt.text(prob * 100 + 0.5, i, f'{prob*100:.2f}%', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return preds\n",
    "\n",
    "# Example: Try different years\n",
    "predict_any_season(2022)\n",
    "\n",
    "# Uncomment to try other years:\n",
    "# predict_any_season(2021)\n",
    "# predict_any_season(2020)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
