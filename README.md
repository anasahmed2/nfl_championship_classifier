# NFL Championship Classifier ğŸˆ

Machine Learning system to predict NFL Super Bowl champions using **XGBoost** and historical team performance data.

---

## ğŸ¯ Project Overview

This project implements a **supervised classification** model that predicts the probability of each NFL team winning the Super Bowl based on season statistics.

### Key Features
- âœ… **XGBoost** gradient boosting classifier
- âœ… **Time-based cross-validation** (prevents data leakage)
- âœ… **Hyperparameter tuning** with GridSearchCV
- âœ… **Multiple evaluation metrics** (Log Loss, ROC-AUC, Brier Score)
- âœ… **Feature engineering** with lag features and derived metrics
- âœ… **Comprehensive visualizations** (7 different plot types)
- âœ… **Historical validation** against actual Super Bowl winners

---

## ğŸ“Š Machine Learning Approach

### Problem Type
**Binary Classification (per team)**
- Target: `Won_SB` (1 = Champion, 0 = Not Champion)
- Output: Championship probability for each team

### Model Architecture
- **Algorithm**: XGBoost (eXtreme Gradient Boosting)
- **Reason**: Best for structured/tabular sports data with non-linear relationships
- **Loss Function**: Binary cross-entropy (log loss)

### Validation Strategy
**Time-Based Cross-Validation**
```
Train: 2005-2015 â†’ Test: 2016
Train: 2005-2016 â†’ Test: 2017
Train: 2005-2017 â†’ Test: 2018
...
```
This simulates real-world prediction where we only have past data.

### Features Used
1. **Basic Stats**: Win %, Points For/Against, Point Differential
2. **Derived Features**: Points per game, scoring efficiency
3. **Lag Features**: Previous season performance, year-over-year change
4. **Advanced Metrics**: Strength of schedule (when available)

---

## ğŸš€ Quick Start

### Installation
```powershell
# Clone/navigate to project
cd nfl_championship_classifier

# Install dependencies
pip install pandas requests beautifulsoup4 lxml matplotlib seaborn scikit-learn xgboost
```

### Run Complete Pipeline
```powershell
# Scrape data + Train model + Generate predictions + Create plots
python src/run_pipeline.py
```

### Individual Components
```powershell
# 1. Scrape NFL data
python src/championship_classifier.py

# 2. Prepare data and add labels
python src/data_preparation.py

# 3. Train XGBoost model
python src/train_model.py

# 4. Make predictions
python src/predict.py

# 5. Generate visualizations
python src/visualize.py
```

---

## ğŸ“ Project Structure

```
nfl_championship_classifier/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ championship_classifier.py    # Web scraper (Pro Football Reference)
â”‚   â”œâ”€â”€ data_preparation.py           # Data cleaning + feature engineering
â”‚   â”œâ”€â”€ train_model.py                # XGBoost training pipeline
â”‚   â”œâ”€â”€ predict.py                    # Championship predictions
â”‚   â”œâ”€â”€ visualize.py                  # Plot generation
â”‚   â””â”€â”€ run_pipeline.py               # Master execution script
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ nfl_standings_2005_2024.csv   # Raw scraped data
â”‚   â””â”€â”€ nfl_ml_ready.csv              # Cleaned ML-ready dataset
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ championship_model.pkl         # Trained XGBoost model
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ predictions_2024.csv           # Championship probabilities
â”‚   â”œâ”€â”€ cv_results.csv                 # Time-based CV metrics
â”‚   â””â”€â”€ *.png                          # 7 visualization plots
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“ˆ Evaluation Metrics

| Metric | What It Measures | Why It Matters |
|--------|------------------|----------------|
| **Log Loss** | Probability calibration quality | Lower = better probability estimates |
| **ROC-AUC** | Ranking ability (0-1 scale) | Higher = better at ranking teams |
| **Brier Score** | Mean squared error of probabilities | Lower = more accurate predictions |
| **Accuracy** | Direct prediction correctness | Simple but imbalanced (only 1 winner) |

---

## ğŸ”§ Hyperparameter Tuning

GridSearchCV optimizes:
- `n_estimators`: Number of boosting trees (50-150)
- `max_depth`: Tree depth (2-4)
- `learning_rate`: Step size (0.01-0.1)
- `subsample`: Row sampling fraction (0.7-1.0)
- `colsample_bytree`: Feature sampling fraction (0.7-1.0)
- `min_child_weight`: Regularization (1-5)

---

## ğŸ“Š Generated Visualizations

1. **Win % vs Championship** - Scatter plot showing champion characteristics
2. **Probability Distribution** - Bar chart of championship probabilities by team
3. **CV Performance Timeline** - Model performance across test years
4. **Feature Importance** - XGBoost feature contribution rankings
5. **Champion Statistics** - Box plots comparing champions vs non-champions
6. **Prediction Accuracy** - Historical validation results
7. **Correlation Heatmap** - Feature relationships

---

## ğŸ¯ Example Output

```
ğŸ† Championship Probability Rankings (2024):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Rank  Team                      Championship_Prob  Win_Pct  Point_Diff
  1   Kansas City Chiefs              23.45%        0.688      +123
  2   San Francisco 49ers             18.32%        0.750      +156
  3   Baltimore Ravens                15.67%        0.813      +209
  ...
```

---

## ğŸ§  Design Rationale

### Why XGBoost?
- âœ… Handles **non-linear relationships** (e.g., great offense + bad defense â‰  champion)
- âœ… Robust to **feature interactions**
- âœ… Built-in **regularization** prevents overfitting
- âœ… Industry standard for **tabular data**

### Why Time-Based CV?
- âŒ Random split would **leak future data** into training
- âœ… Mimics **real prediction scenario** (only past data available)
- âœ… More **realistic performance estimates**

### Why Not Other Models?
| Model | Issue |
|-------|-------|
| Linear Regression | Can't capture complex interactions |
| KNN | Poor with high-dimensional sparse data |
| Neural Networks | Needs way more data, harder to interpret |

---

## ğŸ”® Future Enhancements

- [ ] Add **player-level features** (QB rating, injury data)
- [ ] Include **playoff-specific stats** (not just regular season)
- [ ] Implement **Monte Carlo simulation** for playoff paths
- [ ] Add **DVOA** and **advanced analytics** (if scraping expanded)
- [ ] Ensemble with **LightGBM + Random Forest**
- [ ] Real-time **mid-season predictions** as games are played

---

## ğŸ“š Data Source

- **Website**: [Pro Football Reference](https://www.pro-football-reference.com/)
- **Years**: 2005-2024 (20 seasons)
- **Teams**: All 32 NFL teams (per season)
- **Update Method**: Re-run `championship_classifier.py` scraper

---

## âš ï¸ Limitations

1. **Limited features**: Only basic team stats (no QB/player-specific data)
2. **Small dataset**: ~640 team-seasons, only ~19 champions
3. **Class imbalance**: 1 champion vs 31 non-champions per year
4. **Injuries not captured**: Major player injuries can drastically change outcomes
5. **Playoff randomness**: Single-elimination bracket has inherent variance

---

## ğŸ“œ License

This project is for **educational purposes** only. NFL data is property of the NFL and Pro Football Reference.

---

## ğŸ‘¤ Author

**Your Name**
- Project: NFL Championship Prediction System
- Technology Stack: Python, XGBoost, Scikit-Learn, Pandas, Matplotlib

---

## ğŸ™ Acknowledgments

- Pro Football Reference for historical data
- XGBoost development team
- Scikit-learn community

---

**Last Updated**: February 2026
